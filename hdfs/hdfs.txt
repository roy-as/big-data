
1) HDFS不同的集群之间数据拷贝: 
	1.1: 服务器之间数据拷贝操作: scp命令
		从本地服务器将数据发送给远端服务器
			方式1：指定用户名，命令执行后需要再输入密码；
			scp -r local_folder remote_username@remote_ip:remote_folder 

			方式2:没有指定用户名，命令执行后需要输入用户名和密码；
			scp -r local_folder remote_ip:remote_folder 
			注意，如果实现了ssh免密登录之后，则不需要输入密码即可拷贝。

		从远端服务器中将数据发送给本地服务器: 用的不是特别多
			方式1：指定用户名，命令执行后需要再输入密码；
			scp -r remote_username@remote_ip:remote_folder local_folder  

			方式2:没有指定用户名，命令执行后需要输入用户名和密码；
			scp -r remote_ip:remote_folder local_folder  
			注意，如果实现了ssh免密登录之后，则不需要输入密码即可拷贝。

	1.2: 集群之间的数据拷贝的工作:  数据迁移
		hadoop distcp hdfs://node1:8020/jdk-8u241-linux-x64.tar.gz  hdfs://cluster2:8020/
		底层执行MR 完成此处操作

2: HDFS的归档文件操作:  能够会使用
	作用: 用来进行小文件合并的操作

	方式一: 通过 javaAPI操作 实现小文件合并
		使用场景:  同类型的文本数据合并工作
		弊端: 多个文件数据合并在一个文件中, 导致后续进行拆分出现问题

	方式二: 归档文件
		一种类似于window中 zip方案, 将多个文件合并在一个文件中, 后续也可以将文件在解压还原出来

		1. 如何创建归档文件: 
			hadoop archive -archiveName name -p <parent> <src>* <dest>
			例如:
				hadoop archive -archiveName test.har -p /config  /outputdir
				描述: 
					创建一个归档文件为 test.har  将这个文件放置到 outputdir目录下, 归档文件中内容为 config目录下内容
		2. 如何查看归档文件中内容: 
			看一下 归档中主要构成:
				hadoop fs -ls /outputdir/test.har
			查看归档文件中, 原来文件内容:
				hadoop fs -ls har://hdfs-node1:8020/outputdir/test.har
				上述可以简写为: 
					hadoop fs -ls har:///outputdir/test.har 

		3. 如何将归档文件原有数据解压出来:
			hadoop fs -mkdir /config2
			hadoop fs -cp har:///outputdir/test.har/*    /config2
		

	相关的注意事项:
		1.Hadoop archives是特殊的档案格式。一个Hadoop archive对应一个文件系统目录。Hadoop archive的扩展名是*.har；
		2.创建archives本质是运行一个Map/Reduce任务，所以应该在Hadoop集群上运行创建档案的命令，要提前启动Yarn集群； 
		3.创建archive文件要消耗和原文件一样多的硬盘空间；
		4.archive文件不支持压缩，尽管archive文件看起来像已经被压缩过；
		5.archive文件一旦创建就无法改变，要修改的话，需要创建新的archive文件。事实上，一般不会再对存档后的文件进行修改，因为它们是定期存档的，比如每周或每日；
		6.当创建archive时，源文件不会被更改或删除；

4. HDFS的数据快照功能:  实际生产中使用较少
	主要是对HDFS的文件夹 进行拍摄快照, 提供一种备份的操作

	HDFS的数据快照功能 主要是采用的差异化快照: 
		首先对某一个文件夹拍摄快照, 此时在快照文件中不会进行任何记录操作, 只有当这个拍摄快照文件夹中
			进行相关的操作, 此时快照中才会记录修改的内容即可

	默认情况: 文件夹不支持拍摄快照
	注意: 快照只能给文件夹拍摄, 不允许给文件拍摄快照
	HDFS的快照的相关的操作: 
		1、开启指定目录的快照功能
		hdfs dfsadmin  -allowSnapshot  路径 
		2、禁用指定目录的快照功能（默认就是禁用状态）
		hdfs dfsadmin  -disallowSnapshot  路径
		3、给某个路径创建快照snapshot
		hdfs dfs -createSnapshot  路径
		4、指定快照名称进行创建快照snapshot
		hdfs dfs  -createSanpshot 路径 名称    
		5、给快照重新命名
		hdfs dfs  -renameSnapshot  路径 旧名称  新名称
		6、列出当前用户所有可快照目录
		hdfs lsSnapshottableDir  
		7、比较两个快照的目录不同之处
		hdfs snapshotDiff  路径1  路径2
		8、删除快照snapshot
		hdfs dfs -deleteSnapshot <path> <snapshotName> 

3) HDFS的垃圾桶的机制:
	为什么文件系统需要有垃圾桶呢? 给一个反悔机会

	hdfs的回收站, 默认情况下 7天之后, 自动删除掉 此时间也可以在 core-site.xml中进行修改配置的
		<property>  
		    <name>fs.trash.interval</name>  
		    <value>10080</value>  
		</property>  
		/*单位为分钟*/
	如果想对回收站进行还原, 只需要进入回收站, 将对应数据移动到原有目录下即可还原操作

	如果想要手动清空回收站: 此操作慎用 一般不做此操作
		hadoop fs -expunge

	注意:
		如果使用 java API的中 delete操作, 直接跳过回收站, 直接删除数据